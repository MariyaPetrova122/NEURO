{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация текстов\n",
    "#### М.Горький \"Трое\", М.Горький \"Старуха Изергиль\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Выполнили: Цендякова Светлана, Петрова Мария"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Горький Максим Трое \n",
      "А.М.Горький Трое Среди лесов Керженца рассеяно много одиноких могил; в них тлеют кости старцев, людей древнего благочестия, об одном из таких старцев - Антипе - в деревнях, на Керженце, рассказывают: Суровый характером, богатый мужик Антипа Лунёв, дожив во грехе мирском до пятидесяти лет, задумался крепко, затосковал и, бросив семью, ушёл в леса. Там, на краю крутого оврага, он срубил себе келью и жил в ней восемь лет кряду, зиму и лето, не допуская к себе никого: ни знакомых, ни родных своих. Порою люди, заблудясь в лесу, случайно выходили к его келье и видели Антипу: он молился, стоя на коленях у порога её. Был он страшный: иссох в посте и молитве и весь, как зверь, оброс волосами. Завидев человека, он поднимался на ноги и молча кланялся ему до земли. Если его спрашивали, как выйти из леса, он без слов указывал рукою дорогу, ещё кланялся человеку до земли и, уходя в свою келью, запирался в ней. За восемь лет его видели часто, но никто никогда не слыхал его голоса. Жена и дети приходили к нему; он принимал от них пищу и одежду и, как всем людям, кланялся им земно, но, как всем людям, им тоже ни слова не сказал. Умер он в год, когда разоряли скиты, и смерть его была такова: Приехал в лес исправник с командой, и увидали они, что стоит Антипа среди кельи на коленях, безмолвно молится. - Ты! - крикнул исправник. - Уходи! Ломать будем твоё логовище!.. - Но Антипа не слышал его. И сколько ни кричал исправник - ни слова не ответил ему старец. Исправник велел в\n"
     ]
    }
   ],
   "source": [
    "with open(\"troe.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Делаем предобработку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество слов 80346\n"
     ]
    }
   ],
   "source": [
    "text = text.lower() #нижний регистр\n",
    "words = [word for word in re.split('[ »–\\—«\\-\\n\\t\\r,\\.\\?!:;\\*\\'\\\"“”\\[\\]\\(\\)/]', text) if word != ''] #сделали список слов\n",
    "print('Количество слов', len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сделаем поменьше, экономии времени ради"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество слов 25000\n",
      "Количество уникальных слов 7307\n"
     ]
    }
   ],
   "source": [
    "words = words[:25000]\n",
    "tokens = set(words)\n",
    "print('Количество слов', len(words))\n",
    "print('Количество уникальных слов', len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Далее присваиваем словам индексы, делаем таблицу соответствия слово-индекс, индекс-слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tokens = len(tokens)\n",
    "\n",
    "token2index = dict((t, i) for i, t in enumerate(tokens))\n",
    "index2token = dict((i, t) for i, t in enumerate(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создаем входные строки и метки. Проходим по тексту с шагом=1 и выделяем отрезки SEQLEN=10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входных токенов 24993\n",
      "Слова-метки 24993\n"
     ]
    }
   ],
   "source": [
    "SEQLEN = 7\n",
    "STEP = 1\n",
    "\n",
    "input_tokens = []\n",
    "label_tokens = []\n",
    "for i in range(0, len(words) - SEQLEN, STEP):\n",
    "    input_tokens.append(words[i:i + SEQLEN])\n",
    "    label_tokens.append(words[i + SEQLEN]) #слова-метки\n",
    "    \n",
    "print('Входных токенов', len(input_tokens)) #количество различных возможных последовательностей\n",
    "print('Слова-метки', len(label_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿горький максим трое а м горький трое -> среди\n",
      "максим трое а м горький трое среди -> лесов\n",
      "трое а м горький трое среди лесов -> керженца\n",
      "а м горький трое среди лесов керженца -> рассеяно\n",
      "м горький трое среди лесов керженца рассеяно -> много\n",
      "горький трое среди лесов керженца рассеяно много -> одиноких\n",
      "трое среди лесов керженца рассеяно много одиноких -> могил\n",
      "среди лесов керженца рассеяно много одиноких могил -> в\n",
      "лесов керженца рассеяно много одиноких могил в -> них\n",
      "керженца рассеяно много одиноких могил в них -> тлеют\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(' '.join(input_tokens[i]), '->', label_tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Превращаем входные строки в тензоры и метки в векторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_tokens), SEQLEN, nb_tokens), dtype = np.bool)\n",
    "y = np.zeros((len(input_tokens), nb_tokens), dtype = np.bool)\n",
    "\n",
    "for i, input_tok(input_tokens):\n",
    "    for j, t in enumerate(input_token):[i, j, token2index[t]] = 1\n",
    "    y[i, token2index[label_tokens[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучаем модель в течение 25 итераций по 1 эпохе, в конце каждой эпохи тестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_tokens),\n",
    "                    unroll=True))\n",
    "model.add(Dense(nb_tokens))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 105s 4ms/step - loss: 7.7732\n",
      "Generating from seed: друг друга не имея в этом надобности\n",
      "друг друга не имея в этом надобности и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 76s 3ms/step - loss: 7.4210\n",
      "Generating from seed: ни о чём не думая слушал пение\n",
      "ни о чём не думая слушал пение и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и и \n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 75s 3ms/step - loss: 7.1108\n",
      "Generating from seed: на мальчика нехорошими глазами что сволочь здорово\n",
      "на мальчика нехорошими глазами что сволочь здорово и и и и в и он и в и и и и и и в в в и и и и и и в в в и и и и и и в в в и и и и и и в в в и и и и и и в в в и и и и и и в в в и и и и и и в в в и и и и и и в в в и и и и и и в в в и и и и и и в в в и \n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 77s 3ms/step - loss: 6.8870\n",
      "Generating from seed: не сирота а просто один буду жить\n",
      "не сирота а просто один буду жить и него и не не ни в него он в и и и и и и в в в в в слова и и чувство и и и в в то в в слова и и и и и в в в в в слова и и чувство и и и в в то в в слова и и и и и в в в в в слова и и чувство и и и в в то в в слова и и и и и в в в в в слова и и чувство и и и в в то \n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 79s 3ms/step - loss: 6.7278\n",
      "Generating from seed: скажу строго молвил полицейский всё это ты\n",
      "скажу строго молвил полицейский всё это ты то всё выдохнул а не мне а он он не дядей а и так и в а и него в него в и а в в и к в в он в в в и и и и в в в в в в в и и и в в в в в в в и и и в в в в в в в и и и в в в в в в в и и и в в в в в в в и и и в в в в в в в и и и в в \n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 88s 4ms/step - loss: 6.5726\n",
      "Generating from seed: же кучер все в доме говорили неполным\n",
      "же кучер все в доме говорили неполным а и что и жалобой а я а не я не и я я а не я а то я я я не я а я я тебе я не я я я я я я ты я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я я \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 82s 3ms/step - loss: 6.4044\n",
      "Generating from seed: ещё будучи подростком приобрёл в селе прозвище\n",
      "ещё будучи подростком приобрёл в селе прозвище желание в нём илье и было и в к он в в он за на в к к и и илье у что в него в него и и как чувство в когда а он он то в неё и и к к он в же он то на него и на и и в нему он в он него в и картину и к и о что то в в не было и он он на в нём и него и к к на в он а то на него и и и он в когда он него в \n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 86s 3ms/step - loss: 6.2148\n",
      "Generating from seed: я живой того добьюсь как до чёртиков\n",
      "я живой того добьюсь как до чёртиков молиться и а а в тоже с а а илья так и с не а а а на него в и а а я он а не илья ты так я илья а что ты вот и я а а я ты яков то ты ты так я я я я вот ты ты ты я я ты я вот я тебе ты я что ты что я я что ты я ты ты я ты я мне я вот что я тебе я тебе ты как ты я я я я я я тебе ты ты ты ты я \n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 96s 4ms/step - loss: 6.0196\n",
      "Generating from seed: понять не били меня милого только печкой\n",
      "понять не били меня милого только печкой а но я в вопрос и илья его он с кухню но когда не него и ты не он в не илье не надо а на в нём он не него за он от до в не лицо и на из не мог но его было когда нему нём жизнь в в точно и его за него к в он было лицо в он и в глаза и как в на в по за него с к за в было с в было было его в было и в нём он в в точно и от до на от в \n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 86s 3ms/step - loss: 5.8287\n",
      "Generating from seed: ещё люди не обращали на него столько\n",
      "ещё люди не обращали на него столько только как эх на в трактире его и и зачем и когда его ней а время что него в не голос я и он а что а я так в глаза а ты яков страшно и по ладно яков он в ней в ним не меня к по но в всё а я не его что и ты так мне что не ты вот мне я мне а я мне я тебе ты нет так ты мне ты я мне ты так не вот мне ты вот не яков а я вот мне яков а я так ты я ты \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 84s 3ms/step - loss: 5.6511\n",
      "Generating from seed: маленький понимай что говоришь а как ты\n",
      "маленький понимай что говоришь а как ты меня с знаю я ты не мне илья ты как не надо я что не тебя как ты меня ты что что ты не не я не ты сказал вот что что ты я не то и что яков мне не нём что что ты я вот не до что яков мне ты на то не ты я вот не когда что вот что ты на него к ты на я не неё от не вот что ты то же что то на не надо на не он сказал что ты меня что в что илья я не бы что \n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 87s 3ms/step - loss: 5.4870\n",
      "Generating from seed: старцу взял его за волосы антипа вскинув\n",
      "старцу взял его за волосы антипа вскинув головой и него что сказал его я она то не ты я не кто но он ты мне кто на него что на мне и него на не о на мне то илье что в а на потом в же что и смотрел на голосом что и илья его ильи что говорил а когда не яков как ты его всех когда а но не это не него он его что а что он будет на илью о смотрел и на илья он в был ильи за когда на и но на на на дом ему его он он за как \n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 90s 4ms/step - loss: 5.3375\n",
      "Generating from seed: промолчал а сейчас я тебе ещё дам\n",
      "промолчал а сейчас я тебе ещё дам терентий ты как кто в на в яков мне но так к и и я до он шёл же ты кто тебе я было глаза яков мне тебе так кто что на я мне ей и мне ты что я вот я это мне мне что ты ты ты я вот мне ты это это мне ты это вот это мне я вот мне я ты я и ты я мне ты мне ты яков мне ты мне это вот мне я мне тебе и я я мне ты мне мне ты мне ты мне мне я мне это мне \n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 80s 3ms/step - loss: 5.2084\n",
      "Generating from seed: коровы и хотя от матицы всегда пахло\n",
      "коровы и хотя от матицы всегда пахло ему у не даже стало и сердце а он то от он его и и илья то и илья он не сказал а илья не что илья же а с ну а а а что я ничего а я я я илья ты я я я я ты что вот я я ты я вот а я ты ты мне я я илья ты вот я тебе илья ты ну это это а я это мне а то я илья ты то илья я илья ты что не я что ты ну не а что а ты мне сказал а \n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 81s 3ms/step - loss: 5.0891\n",
      "Generating from seed: воскликнула женщина что это кто же будет\n",
      "воскликнула женщина что это кто же будет сказал на ты мне так не тебя не я вот всё только а тебя что так и не стало яков тебя ему не них а всё не тебя кто и а сказал как ты я так то яков все ничего не кто и и сказал вот яков и так то потом илья у меня то яков и илья а да а говорил сказал стал тоже яков я и терентий себя за в меня кто то смотрел на люди ты и него во а как кто вот него от его яков но так и голову из он даже и яков их \n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24993/24993 [==============================] - 81s 3ms/step - loss: 4.9870\n",
      "Generating from seed: приходила матица принося с собой булки чай\n",
      "приходила матица принося с собой булки чай ему а потом не даже с еремея о сказал а то его тоже с не илья своей то он голову что в илье за и и её что в о был он с она а в за что было сказал и его у с с ним он с когда как из за потом его из однажды то не с еремей сказал илья илья он его на глядя и он он с видел что сказал с ему и с о ты с он но с с ну что с его он сказал ничего а он же что и бы и её \n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 77s 3ms/step - loss: 4.8948\n",
      "Generating from seed: жизнь в доме но илье захотелось узнать\n",
      "жизнь в доме но илье захотелось узнать что она и то и он спросил яков но в на яков и я и что и что как тебе кто тоже что и так да и я в люди то и я тебе кто к кто как тебе и и так и него не илью время а не него что нет со и яков ну не мне ей вот ты мне а я уж это это тебе уж тебе ей ты что то что и меня это и что и ты ты и я что что яков что это тебе кто и что как что то и вот и \n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 81s 3ms/step - loss: 4.8087\n",
      "Generating from seed: не выигрывает а человек пропадёт которых больше\n",
      "не выигрывает а человек пропадёт которых больше ничего и за илья ты же илья то за илья что что у не голову люди что а и как в её он да что это у в она а и так был то от илья своей то и в было у ему в был что в и он за от в что всё только и был что у что в это его в и да что в то что всё уж всё что у тебя говорил а маша как терентий в ты и с сказал илья то всё это все не с что всё как был у в сказал \n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 80s 3ms/step - loss: 4.7299\n",
      "Generating from seed: лежит да и того я не добьюсь\n",
      "лежит да и того я не добьюсь глазами я кто илья так а со всё кто него а и так в как него не воскликнул то и он илья а ты ты сам что на так яков что тебе в люди у и меня да всё в себе то не ты где там у когда он вот что то вот из дом это и зачем всё и себе её мне терентий что да что но я тебе в терентий и его что тебе и он в так в да он только вдруг у и у всё ему с его то глаза она он за сказал в всё \n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 81s 3ms/step - loss: 4.6480\n",
      "Generating from seed: церкви растворялась на паперть вылетала душистая тёплая\n",
      "церкви растворялась на паперть вылетала душистая тёплая он матица она ласково за мальчика и ты и это и по ему это вот ты был это его будет ты это у в то ты ты мне был она у сказал вот не ней к глаза как где он ты к то я не сказал ты что не тебя кто ты не мне что ты ты не ну не человек ты вот вот же сказал и так вот это это лицо где а всё у же мне ты сказал тебе а это ты вот тебе на так ты мне вот же меня у не тебе вот с что я \n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 81s 3ms/step - loss: 4.5711\n",
      "Generating from seed: к жене избитый оборванный голодный умерла мать\n",
      "к жене избитый оборванный голодный умерла мать якова на неё по ней на яков в их же из к у мне но ка очень и и как до мальчику жизнь да что у из из было а я и она яков и да так то яков и меня им и потом у тебе ты а он у где да так у не и я эх я потом я что не и и ей не кто он что то ка и да него и а то на так я то за только что у не то то и с когда сказал его то то кто ка однажды люди \n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 84s 3ms/step - loss: 4.4960\n",
      "Generating from seed: вошёл в трактир то услыхал что перфишка\n",
      "вошёл в трактир то услыхал что перфишка до на страшно и его что и и спросил он то не они время то и в сидел он терентия в то нибудь он и в еремея за точно как это они это с я он этом он что как из так тоже же то так савёл вот и не лицо и потом но это же как вот то а что не и его это её пашка что в то от с как же что у нём из к не мальчика с она до илье же в она от он в от мальчика но он не что него из она \n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 84s 3ms/step - loss: 4.4274\n",
      "Generating from seed: в городском саду из всех детей на\n",
      "в городском саду из всех детей на дворе кроме ильи не неё только с у с но по в стало спросил она из он горбун чем всё голос и яков тебе жить и и я кто на меня жить кто ты и вот что в жить вот вот всё это хозяина матица жить это он и и около на спросил не ты своей им яков ну он чего но в так не сказал ты бы что всё того ты где что в громко да илья очень в так а в я куда да всё того тут всё ему петруха я от илья как как а но это \n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 84s 3ms/step - loss: 4.3599\n",
      "Generating from seed: щёлкнул его пальцем по носу и угрожающе\n",
      "щёлкнул его пальцем по носу и угрожающе спросил кто тебе да а так этот я вот так я и вдруг за про как меня ему что теперь не всё да я он нет в тоже да что кто тебе ей и им я как они всё так что его бы у головой да всё что ты как она больше я да о сказал сказал спросил и как я ну где бы с это тебе это сказал что в спросил же меня есть куда о ка я что не и в то на это так же что у сказал было у и стихи все в где все да \n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "24993/24993 [==============================] - 78s 3ms/step - loss: 4.2998\n",
      "Generating from seed: снова сел на пол голова у него\n",
      "снова сел на пол голова у него её был что у на они лицо к в с сапожник он или это не и она в это с стало то все и с стало спросил в сказал илья них спросил всё на мне илья ему а на и в уж ему себя и все чем а маша себя на голову всегда и с мальчик и не её в однажды сказал всё он же к он его терентий в что и лицо на он что не терентий было это на а так что в все стало только было только и будет в в с не стало а ты он \n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    test_idx = np.random.randint(len(input_tokens))\n",
    "    test_tokens = input_tokens[test_idx]\n",
    "    print(\"Generating from seed: %s\" % ' '.join(test_tokens))\n",
    "    print(' '.join(test_tokens), end=\" \")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_tokens))\n",
    "        for j, t in enumerate(test_tokens):\n",
    "            Xtest[0, j, token2index[t]] = 1    #формируем вектор для Xtest\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2token[np.argmax(pred)]\n",
    "        print(ypred, end=\" \")\n",
    "        \n",
    "        test_tokens.append(ypred)    #добавляем предсказанное слово в последовательность\n",
    "        test_tokens = test_tokens[1:]    #отбрасываем первое слово старой последовательности\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загружаем другой текст автора, проводим предобработку по аналогии с тем, что делали в первый раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I\n",
      "\n",
      "\n",
      "Я слышал эти рассказы под Аккерманом, в Бессарабии, на морском берегу.\n",
      "Однажды вечером, кончив дневной сбор винограда, партия молдаван, с которой я работал, ушла на берег моря, а я и старуха Изергиль остались под густой тенью виноградных лоз и, лежа на земле, молчали, глядя, как тают в голубой мгле ночи силуэты тех людей, что пошли к морю.\n",
      "Они шли, пели и смеялись; мужчины – бронзовые, с пышными, черными усами и густыми кудрями до плеч, в коротких куртках и широких шароварах; женщины и девушки – веселые, гибкие, с темно-синими глазами, тоже бронзовые. Их волосы, шелковые и черные, были распущены, ветер, теплый и легкий, играя ими, звякал монетами, вплетенными в них. Ветер тек широкой, ровной волной, но иногда он точно прыгал через что-то невидимое и, рождая сильный порыв, развевал волосы женщин в фантастические гривы, вздымавшиеся вокруг их голов. Это делало женщин странными и сказочными. Они уходили все дальше от нас, а ночь и фантазия одевали их все прекраснее.\n",
      "Кто-то играл на скрипке… девушка пела мягким контральто, слышался смех…\n",
      "Воздух был пропитан острым запахом моря и жирными испарениями земли, незадолго до вечера обильно смоченной дождем. Еще и теперь по небу бродили обрывки туч, пышные, странных очертаний и красок, тут – мягкие, как клубы дыма, сизые и пепельно-голубые, там – резкие, как обломки скал, матово-черные или коричневые. Между ними ласково блестели темно-голубые клочки неба, украшенные золотыми крапинками звезд. Все это – звуки и запахи, тучи и лю\n"
     ]
    }
   ],
   "source": [
    "with open(\"staruha_izergil.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_text = f.read()\n",
    "    \n",
    "print(test_text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test_text.lower()    #нижний регистр\n",
    "test_words = [word for word in re.split('[ »\\—«\\-\\n\\t\\r,\\.\\?!:;\\*\\'\\\"“”\\[\\]\\(\\)/]', test_text) if word != ''] #список слов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576\n"
     ]
    }
   ],
   "source": [
    "test_tokens = set(test_words)\n",
    "print(len(test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные токены 7120\n",
      "Слова-метки 7120\n"
     ]
    }
   ],
   "source": [
    "test_inputs = []\n",
    "test_labels = []\n",
    "for i in range(0, len(test_words) - SEQLEN, STEP):\n",
    "    test_inputs.append(test_words[i:i + SEQLEN])\n",
    "    test_labels.append(test_words[i + SEQLEN])\n",
    "    \n",
    "print('Входные токены', len(test_inputs))\n",
    "print('Слова-метки', len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(probs):\n",
    "    logsum = 0\n",
    "    for prob in probs:\n",
    "        log_prob = math.log2(prob)\n",
    "        logsum += log_prob\n",
    "    l = logsum/len(probs)\n",
    "    perplex = math.pow(2, -l)\n",
    "    return perplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    probs = []\n",
    "    for i in range(len(test_inputs)):\n",
    "        test_input, test_label = test_inputs[i], test_labels[i]\n",
    "        test_tensor = np.zeros((1, SEQLEN, nb_tokens))\n",
    "    \n",
    "        for j, t in enumerate(test_input):\n",
    "            if t in token2index:  \n",
    "                test_tensor[0, j, token2index[t]] = 1    #формируем тензор для каджой последовательности SEQLEN слов тестового текста\n",
    "        #print('test_tensor.shape =', test_tensor.shape)\n",
    "        red = model.predict(test_tensor, verbose=0)[0]\n",
    "        #print(pred, '\\n')\n",
    "        if test_label in token2index:\n",
    "            prob = pred[token2index[test_label]]\n",
    "            probs.append(prob)\n",
    "    prplx = perplexity(probs)\n",
    "    return prplx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Перплексия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168.5744765598174\n"
     ]
    }
   ],
   "source": [
    "print(eval_model(model)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24993/24993 [==============================] - 391s 16ms/step - loss: 7.8773\n",
      "\n",
      "Epoch 00001: loss improved from inf to 7.87729, saving model to weights-improvement-01-7.8773.hdf5\n",
      "Epoch 2/20\n",
      "24993/24993 [==============================] - 385s 15ms/step - loss: 7.4185\n",
      "\n",
      "Epoch 00002: loss improved from 7.87729 to 7.41850, saving model to weights-improvement-02-7.4185.hdf5\n",
      "Epoch 3/20\n",
      "24993/24993 [==============================] - 389s 16ms/step - loss: 7.3316\n",
      "\n",
      "Epoch 00003: loss improved from 7.41850 to 7.33162, saving model to weights-improvement-03-7.3316.hdf5\n",
      "Epoch 4/20\n",
      "24993/24993 [==============================] - 380s 15ms/step - loss: 7.2624\n",
      "\n",
      "Epoch 00004: loss improved from 7.33162 to 7.26243, saving model to weights-improvement-04-7.2624.hdf5\n",
      "Epoch 5/20\n",
      "24993/24993 [==============================] - 370s 15ms/step - loss: 7.1994\n",
      "\n",
      "Epoch 00005: loss improved from 7.26243 to 7.19945, saving model to weights-improvement-05-7.1994.hdf5\n",
      "Epoch 6/20\n",
      "24993/24993 [==============================] - 395s 16ms/step - loss: 7.1088\n",
      "\n",
      "Epoch 00006: loss improved from 7.19945 to 7.10885, saving model to weights-improvement-06-7.1088.hdf5\n",
      "Epoch 7/20\n",
      "24993/24993 [==============================] - 398s 16ms/step - loss: 6.9075\n",
      "\n",
      "Epoch 00007: loss improved from 7.10885 to 6.90747, saving model to weights-improvement-07-6.9075.hdf5\n",
      "Epoch 8/20\n",
      "24993/24993 [==============================] - 399s 16ms/step - loss: 6.5991\n",
      "\n",
      "Epoch 00008: loss improved from 6.90747 to 6.59911, saving model to weights-improvement-08-6.5991.hdf5\n",
      "Epoch 9/20\n",
      "24993/24993 [==============================] - 396s 16ms/step - loss: 6.1842\n",
      "\n",
      "Epoch 00009: loss improved from 6.59911 to 6.18416, saving model to weights-improvement-09-6.1842.hdf5\n",
      "Epoch 10/20\n",
      "24993/24993 [==============================] - 468s 19ms/step - loss: 5.6815\n",
      "\n",
      "Epoch 00010: loss improved from 6.18416 to 5.68148, saving model to weights-improvement-10-5.6815.hdf5\n",
      "Epoch 11/20\n",
      "24993/24993 [==============================] - 410s 16ms/step - loss: 5.1187\n",
      "\n",
      "Epoch 00011: loss improved from 5.68148 to 5.11873, saving model to weights-improvement-11-5.1187.hdf5\n",
      "Epoch 12/20\n",
      "24993/24993 [==============================] - 393s 16ms/step - loss: 4.5308\n",
      "\n",
      "Epoch 00012: loss improved from 5.11873 to 4.53079, saving model to weights-improvement-12-4.5308.hdf5\n",
      "Epoch 13/20\n",
      "24993/24993 [==============================] - 415s 17ms/step - loss: 3.9094\n",
      "\n",
      "Epoch 00013: loss improved from 4.53079 to 3.90944, saving model to weights-improvement-13-3.9094.hdf5\n",
      "Epoch 14/20\n",
      "24993/24993 [==============================] - 397s 16ms/step - loss: 3.3127\n",
      "\n",
      "Epoch 00014: loss improved from 3.90944 to 3.31270, saving model to weights-improvement-14-3.3127.hdf5\n",
      "Epoch 15/20\n",
      "24993/24993 [==============================] - 379s 15ms/step - loss: 2.7262\n",
      "\n",
      "Epoch 00015: loss improved from 3.31270 to 2.72620, saving model to weights-improvement-15-2.7262.hdf5\n",
      "Epoch 16/20\n",
      "24993/24993 [==============================] - 388s 16ms/step - loss: 2.1856\n",
      "\n",
      "Epoch 00016: loss improved from 2.72620 to 2.18559, saving model to weights-improvement-16-2.1856.hdf5\n",
      "Epoch 17/20\n",
      "24993/24993 [==============================] - 394s 16ms/step - loss: 1.7237\n",
      "\n",
      "Epoch 00017: loss improved from 2.18559 to 1.72374, saving model to weights-improvement-17-1.7237.hdf5\n",
      "Epoch 18/20\n",
      "24993/24993 [==============================] - 389s 16ms/step - loss: 1.3336\n",
      "\n",
      "Epoch 00018: loss improved from 1.72374 to 1.33365, saving model to weights-improvement-18-1.3336.hdf5\n",
      "Epoch 19/20\n",
      "24993/24993 [==============================] - 345s 14ms/step - loss: 1.0434\n",
      "\n",
      "Epoch 00019: loss improved from 1.33365 to 1.04338, saving model to weights-improvement-19-1.0434.hdf5\n",
      "Epoch 20/20\n",
      "24993/24993 [==============================] - 468s 19ms/step - loss: 0.8139\n",
      "\n",
      "Epoch 00020: loss improved from 1.04338 to 0.81395, saving model to weights-improvement-20-0.8139.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3cc950d0b8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подгружаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-20-0.8139.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(words)) #словарь соответствий, чтобы преобразовывать индексы в слова\n",
    "int_to_char = tuple(int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-ab23614e6b5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"Seed:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint_to_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# generate characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-ab23614e6b5b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"Seed:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint_to_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# generate characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(X)-1)\n",
    "pattern = X[start]\n",
    "print( \"Seed:\")\n",
    "print( \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print( \"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
